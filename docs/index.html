
<!doctype html>
<html lang="en">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><link href="./Plug-and-Play Diffusion Features for Text-Driven Image-to-Image Translation_files/chalkduster" rel="stylesheet">
<link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üêº</text></svg>">
<style>
	@import url('https://fonts.cdnfonts.com/css/chalkduster');
</style>
<head>
	<!-- Required meta tags -->
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
	<meta name="google-site-verification" content="eGDOZ_6azobM9Vcl7r072IFo1FJ-TfNvGkmz6YbLCLo" />

	<!-- Bootstrap CSS -->
	<link href="./html_pages/resources/bootstrap.min.css" rel="stylesheet">
	<link href="./html_pages/resources/stylesheet.css" rel="stylesheet">
	<script src="js/jquery-2.1.3.min.js"> </script>

	<title>Panda-70M</title>
</head>
	
<body data-new-gr-c-s-check-loaded="14.1110.0" data-gr-ext-installed="">
	<header>
		<nav>
			<a class="h5 pt-1" style="margin-left: 10px; color: #fff !important;" href="#Panda70M">&#128060; Panda-70M</a>
		</nav>
		<nav>
			<a href="#download">Download</a>
			<a href="#presentation">Presentation</a>
			<a href="#collection">Collection</a>
			<a href="#demo">Demo</a>
			<a href="#statistic">Statistic</a>
			<a href="#performance">Performance</a>
			<a href="#acknowledgement">Acknowledgement</a>
		</nav>
	</header>

	<section class="jumbotron text-center pb-2" id="Panda70M">
		<div class="container">
			<br><br><br>
			<h1 class="jumbotron-heading" style="font-size: 5.5rem">&#128060; Panda-70M</h1>
			<h5 class="pt-1" style="font-size: 2rem; font-weight: normal">A Large-Scale Dataset with 70M High-Quality Video-Caption Pairs</h5>
			<br><br>
			<a href="https://tsaishien-chen.github.io/" style="font-size: 1.2rem; color: white !important;">Tsai-Shien Chen</a>,
			<a href="https://aliaksandrsiarohin.github.io/aliaksandr-siarohin-website/" style="font-size: 1.2rem; color: white !important;">Aliaksandr Siarohin</a>,
			<a href="https://www.willimenapace.com/" style="font-size: 1.2rem; color: white !important;">Willi Menapace</a>,
			<a href="https://edeyneka.github.io/" style="font-size: 1.2rem; color: white !important;">Ekaterina Deyneka</a>,
			<a href="https://www.linkedin.com/in/hsiang-wei-chao" style="font-size: 1.2rem; color: white !important;">Hsiang-wei Chao</a>,
			<br>
			<a href="https://www.linkedin.com/in/logan-jeon" style="font-size: 1.2rem; color: white !important;">Byung Eun Jeon</a>,
			<a href="https://yuwfan.github.io/" style="font-size: 1.2rem; color: white !important;">Yuwei Fang</a>,
			<a href="http://hsinyinglee.com/" style="font-size: 1.2rem; color: white !important;">Hsin-Ying Lee</a>,
			<a href="https://alanspike.github.io/" style="font-size: 1.2rem; color: white !important;">Jian Ren</a>,
			<a href="https://faculty.ucmerced.edu/mhyang/" style="font-size: 1.2rem; color: white !important;">Ming-Hsuan Yang</a>,
			<a href="http://www.stulyakov.com/" style="font-size: 1.2rem; color: white !important;">Sergey Tulyakov</a>
			<br><br>
			<a style="font-size: 1.2rem; color: white !important;"><i>CVPR 2024</i></a>
			<br><br>
			<a href="https://research.snap.com/team/category/creative-vision"><img class="paper-btn" src="./assets/snap.svg" style="height: 80px; width: auto; background-color: #18191a;"></a>
			<a href="https://www.ucmerced.edu/"><img class="paper-btn" src="./assets/ucmerced.svg" style="height: 80px; width: auto; background-color: #18191a;"></a>
			<br><br>
				<div class="paper-btn-parent">
				<a class="paper-btn" href="https://arxiv.org/abs/2402.19479">Read research paper</a>
				<a class="paper-btn" style="width: 80px" href="https://github.com/snap-research/Panda-70M">Github</a>
				<a class="paper-btn" href="./more_samples.html">View more samples</a>
			</div>
			<br><br><br>
		</div>
	</section>

	<div style="display: flex; justify-content: space-around; flex-wrap: wrap; margin-top: -65px;">
		<div class="video-teaser-container">
			<video playsinline autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/CkPpCpixOMI.22.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>A blue off-road truck is driving on a sand dune and jumping into the air.</p>
			</div>
		</div>
		<div class="video-teaser-container">
			<video playsinline autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/Nuia1y8ZfhE.13.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>There are ants tunneling under a thick carpet of moss.</p>
			</div>
		</div>
		<div class="video-teaser-container">
			<video playsinline autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/AIyw1FO1aqs.57.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>A person is holding a long haired dachshund in their arms.</p>
			</div>
		</div>
		<div class="video-teaser-container">
			<video playsinline autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/1rKiSD4A1K4.28.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>There is a river flowing through a forest and the water is flowing downstream.</p>
			</div>
		</div>

		<div class="video-teaser-container" style="margin-top: -6px;">
			<video playsinline autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/7axksThlAok.79.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>A group of basketball players are practicing their shots on the court.</p>
			</div>
		</div>
		<div class="video-teaser-container" style="margin-top: -6px;">
			<video playsinline autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/Kb8ON0iCs38.97.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>A rocket launches into space on the launch pad.</p>
			</div>
		</div>
		<div class="video-teaser-container" style="margin-top: -6px;">
			<video playsinline autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/RYbjJ2TpGMo.10.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>Someone is frying dough balls in a pan with oil.</p>
			</div>
		</div>
		<div class="video-teaser-container" style="margin-top: -6px;">
			<video playsinline autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/AvVDsFBc6bA.0.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>A person is kneading dough and putting jam on it.</p>
			</div>
		</div>

		<div class="video-teaser-container" style="margin-top: -6px;">
			<video playsinline autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/fjSw0PBrtMU.45.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>A person is driving a boat on a river with rocks and waterfalls.</p>
			</div>
		</div>
		<div class="video-teaser-container" style="margin-top: -6px;">
			<video playsinline autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/pKIEP-MOCu0.47.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>A woman is playing golf at an outdoor driving range.</p>
			</div>
		</div>

		<div class="video-teaser-container" style="margin-top: -6px;">
			<video playsinline autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/1NMpoAqzJfY.25.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>It is a rally car driving on a dirt road in the countryside, with people watching from the side of the road.</p>
			</div>
		</div>
		<div class="video-teaser-container" style="margin-top: -6px;">
			<video playsinline autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/5HXiHnvBhI4.30.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>The waves are crashing on the beach and the water is foamy.</p>
			</div>
		</div>
		<div class="video-teaser-container" style="margin-top: -6px;">
			<video playsinline autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/aIPu1xGNbhc.49.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>A rhino and a lion are fighting in the dirt.</p>
			</div>
		</div>
		<div class="video-teaser-container" style="margin-top: -6px;">
			<video playsinline autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/8glWcEuxw3U.1.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>A blue toyota tacoma truck is parked in a parking lot surrounded by trees.</p>
			</div>
		</div>
		<div class="video-teaser-container" style="margin-top: -6px;">
			<video playsinline autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/YYPLi7kGUdU.12.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>A person is making a pie crust on a table.</p>
			</div>
		</div>
		<div class="video-teaser-container" style="margin-top: -6px;">
			<video playsinline autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/6AXZJTgpusY.3.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>A large pile of lava blocking a road.</p>
			</div>
		</div>
		<div class="container text-center footnote">
			We will remove the video samples from our dataset / Github / project webpage / technical presentation as long as you need it. Please contact tsaishienchen at gmail dot com for the request.
		</div>
	</div>

	<section id="download">
		<div class="container text-center" style="margin-top: 10px">
			<h1 class="jumbotron-heading">Download Panda-70M</h1>
			<div style="display: flex; justify-content: space-around; flex-wrap: wrap">
				<table class="download-table">
					<tr>
						<td><a class="paper-btn" style="width: 200px" href="https://drive.google.com/file/d/1pbh8W3qgst9CD7nlPhsH9wmUSWjQlGdW/view?usp=sharing">Training [full] (2.73 GB)</a></td>
						<td>70.7M samples / 167 khrs duration / ~36 TB</td>
					</tr>
					<tr>
						<td><a class="paper-btn" style="width: 200px" href="https://drive.google.com/file/d/1LLOFeYw9nZzjT5aA1Wj4oGi5yHUzwSk5/view?usp=sharing">Training [10M] (504 MB)</a></td>
						<td>10.5M samples / 37.0 khrs duration / ~8.0 TB</td>
					</tr>
					<tr>
						<td><a class="paper-btn" style="width: 200px" href="https://drive.google.com/file/d/1k7NzU6wVNZYl6NxOhLXE7Hz7OrpzNLgB/view?usp=sharing">Training [2M] (118 MB)</a></td>
						<td>2.4M samples / 7.56 khrs duration / ~1.6 TB</td>
					</tr>
					<tr>
						<td><a class="paper-btn" style="width: 200px" href="https://drive.google.com/file/d/1uHR5iXS3Sftzw6AwEhyZ9RefipNzBAzt/view?usp=sharing">Validation (1.2 MB)</a></td>
						<td>6000 samples / 18.5 hrs duration / ~4.0 GB</td>
					</tr>
					<tr>
						<td><a class="paper-btn" style="width: 200px" href="https://drive.google.com/file/d/1BZ9L-157Au1TwmkwlJV8nZQvSRLIiFhq/view?usp=sharing">Testing (1.2 MB)</a></td>
						<td>6000 samples / 18.5 hrs duration / ~4.0 GB</td>
					</tr>
				</table>
			</div>
			<a class="paper-btn" style="width: 260px" href="https://github.com/snap-research/Panda-70M/tree/main/dataset_dataloading">Code for Dataset Downloading</a>
			<p style="font-weight: 200; margin-top: 20px;">
				<b>[üî• Updates (Oct 2024)]</b><br>
				To enhance the training of video generation models, we introduce two additional annotations:<br>
				<b>Desirability Filtering</b> and <b>Shot Boundary Detection</b>. Check <a style="color: white !important;" href="https://github.com/snap-research/Panda-70M?tab=readme-ov-file#-updates-oct-2024"><u>here</u></a> for more details.
			</p>
			<p style="font-weight: 200; margin-top: 20px;">
				The video samples are collected from the publicy available dataset.<br>
				Users must follow <a href="https://raw.githubusercontent.com/microsoft/XPretrain/main/hd-vila-100m/LICENSE" style="color: white !important;"><u>the related license</u></a> to use these video samples.
			</p>
		</div>
	</section>

	<hr class="mt-5">

	<section id="presentation">
		<div class="container text-center" style="margin-top: 10px">
			<div class="youtube-container">
				<iframe src="https://www.youtube.com/embed/m2NQ5k1oTcs?si=jCc8gruNWA_oXNyP&autoplay=0&mute=0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
			</div>
		</div>
	</section>

	<hr class="mt-5">

	<section id="collection">
		<div class="container text-center">
			<h1 class="jumbotron-heading">Collection Pipeline of Panda-70M</h1>
			<div style="display: flex; justify-content: space-around; flex-wrap: wrap; margin-top: 30px">
				<video playsinline autoplay="autoplay" controls="controls" loop="loop" muted="muted" class="video" type="video/mp4" src="./assets/pipeline.mp4" ></video>
				<p style="font-weight: 200; margin-top: 10px;">
					We first collect 3.8M long videos from HD-VILA-100M dataset and split it into 70.8M semantically coherent clips <a style="background-color:#2e5496">(blue)</a>.
					Next, we utilize a number of teacher models with different multimodal inputs to generate multiple captions for a video clip <a style="background-color:#528135">(green)</a>.
					Lastly, we finetune a fine-grained retrieval model to select the caption that best describes the video clip as the annotation <a style="background-color:#bf9001">(yellow)</a>.
				</p>
			</div>
		</div>
	</section>

	<hr class="mt-5">

	<section id="demo">
		<div class="container text-center">	
			<h1 class="jumbotron-heading">Demo of Long Video Annotation</h1>
			<div style="display: flex; justify-content: space-around; flex-wrap: wrap; margin-top: 30px">
				<p style="font-weight: 200; margin-top: 5px;">
					We demo our splitting and captioning algorithm on long videos (scroll to view more).
					The results are shown in the subtitles:
				</p>
			</div>
			<div class="scroll-container" style="margin-top: -1px;">
				<video playsinline autoplay="autoplay" controls="controls" loop="loop" muted="muted" class="video" style="height: 360px; width: auto;">
					<source src="./assets/long_videos/---h-Df_mHE.mp4" type="video/mp4">
					<track src="./assets/long_videos/---h-Df_mHE.vtt" kind="subtitles" label="English" srclang="en" default>
				</video>
				<video playsinline autoplay="autoplay" controls="controls" loop="loop" muted="muted" class="video" style="height: 360px; width: auto;">
					<source src="./assets/long_videos/--8k8hhrnxM.mp4" type="video/mp4">
					<track src="./assets/long_videos/--8k8hhrnxM.vtt" kind="subtitles" label="English" srclang="en" default>
				</video>
				<video playsinline autoplay="autoplay" controls="controls" loop="loop" muted="muted" class="video" style="height: 360px; width: auto;">
					<source src="./assets/long_videos/--8tWKpDDRA.mp4" type="video/mp4">
					<track src="./assets/long_videos/--8tWKpDDRA.vtt" kind="subtitles" label="English" srclang="en" default>
				</video>
				<video playsinline autoplay="autoplay" controls="controls" loop="loop" muted="muted" class="video" style="height: 360px; width: auto;">
					<source src="./assets/long_videos/--5Uy5YZMjA.mp4" type="video/mp4">
					<track src="./assets/long_videos/--5Uy5YZMjA.vtt" kind="subtitles" label="English" srclang="en" default>
				</video>
				<video playsinline autoplay="autoplay" controls="controls" loop="loop" muted="muted" class="video" style="height: 360px; width: auto;">
					<source src="./assets/long_videos/--4kpNp60Sc.mp4" type="video/mp4">
					<track src="./assets/long_videos/--4kpNp60Sc.vtt" kind="subtitles" label="English" srclang="en" default>
				</video>
				<video playsinline autoplay="autoplay" controls="controls" loop="loop" muted="muted" class="video" style="height: 360px; width: auto;">
					<source src="./assets/long_videos/--1ApFKwvjE.mp4" type="video/mp4">
					<track src="./assets/long_videos/--1ApFKwvjE.vtt" kind="subtitles" label="English" srclang="en" default>
				</video>
				<video playsinline autoplay="autoplay" controls="controls" loop="loop" muted="muted" class="video" style="height: 360px; width: auto;">
					<source src="./assets/long_videos/--56B73oBjg.mp4" type="video/mp4">
					<track src="./assets/long_videos/--56B73oBjg.vtt" kind="subtitles" label="English" srclang="en" default>
				</video>
				<video playsinline autoplay="autoplay" controls="controls" loop="loop" muted="muted" class="video" style="height: 360px; width: auto;">
					<source src="./assets/long_videos/--BHf7lnQ_0.mp4" type="video/mp4">
					<track src="./assets/long_videos/--BHf7lnQ_0.vtt" kind="subtitles" label="English" srclang="en" default>
				</video>
			</div>
			<div class="container text-center footnote">
				We will remove the video samples from our dataset / Github / project webpage / technical presentation as long as you need it. Please contact tsaishienchen at gmail dot com for the request.
			</div>
		</div>
	</section>

	<hr class="mt-5">

	<section id="statistic">
		<div class="container text-center">
			<h1 class="jumbotron-heading">Statistic</h1>
			<div style="justify-content: space-around; flex-wrap: wrap; margin-top: 30px">
				<div class="image-item">
					<img src="./assets/statistic.svg" style="margin-top: -20px;">
				</div>
				<div class="image-item">
					<img src="./assets/wordcloud.svg" style="margin-top: 10px; margin-bottom: 10px; width: 90%">
				</div>
			</div>
		</div>
	</section>

	<hr class="mt-5">

	<section id="performance">
		<div class="container text-left">
			<h1 class="jumbotron-heading text-center">Performance</h1>
			<div style="justify-content: space-around; flex-wrap: wrap; margin-top: 30px">
				<div class="image-item">
					<img src="./assets/performance.svg" style="margin-top: -20px; margin-bottom: -20px;">
				</div>
				<p style="font-weight: 200">
					We show the value of Panda-70M on three downstream tasks.
					We compare the models training on the existing dataset and the proposed dataset.
					For a fair comparison, we use the same model architecture, same training configuration, and same amount of training data for all comparisons. For more details:
				</p>
			</div>
			<div style="display: flex; justify-content: space-around; flex-wrap: wrap; margin-top: 20px">
				<a class="paper-btn" href="https://arxiv.org/abs/2402.19479">Read research paper</a>
			</div>
		</div>
	</section>

	<hr class="mt-5">

	<section id="acknowledgement">
		<div class="container text-left">
			<h1 class="jumbotron-heading text-center">Acknowledgement</h1>
			<div style="display: flex; justify-content: space-around; flex-wrap: wrap; margin-top: 20px">
				<p style="font-weight: 200">
					We sincerely thank to everyone who contributed to the meaningful discussions,
					and also extend our gratitude to Snap Inc. for providing the computational resources and fostering a conducive research environment. &#129303; &#128591; &#128123;
				</p>
			</div>
		</div>
	</section>
	
	<div class="container text-center footnote">
		<p style="font-weight: 200; margin-top: 10px;">
			Copyright &#169; 2024 Snap Inc. All rights reserved. This dataset and code is made available by Snap Inc. for non-commercial, research purposes only. Non-commercial means not primarily intended for or directed towards commercial advantage or monetary compensation. Research purposes mean solely for study, instruction, or non-commercial research, testing or validation. No commercial license, whether implied or otherwise, is granted in or to this dataset and code, unless you have entered into a separate agreement with Snap Inc. for such rights. This dataset and code is provided as-is, without warranty of any kind, express or implied, including any warranties of merchantability, title, fitness for a particular purpose, non-infringement, or that the code is free of defects, errors or viruses. In no event will Snap Inc. be liable for any damages or losses of any kind arising from this dataset and code or your use thereof. Any redistribution of this dataset and code must retain or reproduce the above copyright notice, conditions and disclaimer.
		</p>
	</div>

	<script>
		document.addEventListener('DOMContentLoaded', function() {
			const links = document.querySelectorAll('a[href^="#"]');
			
			links.forEach(link => {
			link.addEventListener('click', function(e) {
				e.preventDefault();
				
				const targetId = this.getAttribute('href').substring(1);
				const targetElement = document.getElementById(targetId);
				
				if (targetElement) {
				window.scrollTo({
					top: targetElement.offsetTop,
					behavior: 'smooth'
				});
				}
			});
			});
		});

		document.addEventListener("DOMContentLoaded", function() {
			const imageItems = document.querySelectorAll('.image-item');

			function toggleImageVisibility() {
				const scrollPosition = window.scrollY;

				imageItems.forEach(item => {
					const elementPosition = item.getBoundingClientRect().top;

					if (elementPosition < window.innerHeight * 0.85) {
						item.style.opacity = '1';
					} else {
						item.style.opacity = '0';
					}
				});
			}

			// Listen for scroll events
			window.addEventListener('scroll', function() {
				toggleImageVisibility();
			});
		});

		function updateFontSizeForClass(className) {
			var elements = document.getElementsByClassName(className);
			var screenWidth = window.innerWidth || document.documentElement.clientWidth || document.body.clientWidth;

			for (var i = 0; i < elements.length; i++) {
				// Adjust the threshold and font size as needed
				if (screenWidth < 600) {
					elements[i].style.fontSize = "7px";
				} else if (screenWidth < 800) {
					elements[i].style.fontSize = "10px";
				} else if (screenWidth < 1000) {
					elements[i].style.fontSize = "13px";
				} else {
					elements[i].style.fontSize = "16px";
				}
			}
		}

		// Call the function on page load and window resize
		window.onload = function() {
			updateFontSizeForClass("responsive-text");
		};
		window.onresize = function() {
			updateFontSizeForClass("responsive-text");
		};
	</script>

</body>
</html>
