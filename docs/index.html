
<!doctype html>
<html lang="en">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><link href="./Plug-and-Play Diffusion Features for Text-Driven Image-to-Image Translation_files/chalkduster" rel="stylesheet">
<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üêº</text></svg>">
<style>
	@import url('https://fonts.cdnfonts.com/css/chalkduster');
</style>
<head>
	<!-- Required meta tags -->
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

	<!-- Bootstrap CSS -->
	<link href="./html_pages/resources/bootstrap.min.css" rel="stylesheet">
	<link href="./html_pages/resources/stylesheet.css" rel="stylesheet">
	<script src="js/jquery-2.1.3.min.js"> </script>

	<title>Panda-70M</title>
</head>
	
<body data-new-gr-c-s-check-loaded="14.1110.0" data-gr-ext-installed="">
	<header>
		<nav>
			<a class="h5 pt-1" style="margin-left: 10px; color: #fff !important;" href="#panda70M">&#128060; Panda-70M</a>
		</nav>
		<nav>
			<a href="#download">Download</a>
			<a href="#collection">Collection</a>
			<a href="#demo">Demo</a>
			<a href="#statistic">Statistic</a>
			<a href="#performance">Performance</a>
			<a href="#acknowledgement">Acknowledgement</a>
			<!-- Add more section links as needed -->
		</nav>
	</header>

	<section class="jumbotron text-center pb-2" id="panda70M">
		<div class="container">
			<br><br><br>
			<h1 class="jumbotron-heading" style="font-size: 5.5rem">&#128060; Panda-70M</h1>
			<h5 class="pt-1" style="font-size: 2rem; font-weight: normal">A Large-Scale Dataset with 70M High-Quality Video-Caption Pairs</h5>
			<br><br>
			<a href="https://tsaishien-chen.github.io/" style="font-size: 1.2rem; color: white !important;">Tsai-Shien Chen</a>,
			<a href="https://aliaksandrsiarohin.github.io/aliaksandr-siarohin-website/" style="font-size: 1.2rem; color: white !important;">Aliaksandr Siarohin</a>,
			<a href="https://www.willimenapace.com/" style="font-size: 1.2rem; color: white !important;">Willi Menapace</a>,
			<a href="https://edeyneka.github.io/" style="font-size: 1.2rem; color: white !important;">Ekaterina Deyneka</a>,
			<a href="https://www.linkedin.com/in/hsiang-wei-chao" style="font-size: 1.2rem; color: white !important;">Hsiang-wei Chao</a>,
			<br>
			<a href="https://www.linkedin.com/in/logan-jeon" style="font-size: 1.2rem; color: white !important;">Byung Eun Jeon</a>,
			<a href="https://yuwfan.github.io/" style="font-size: 1.2rem; color: white !important;">Yuwei Fang</a>,
			<a href="http://hsinyinglee.com/" style="font-size: 1.2rem; color: white !important;">Hsin-Ying Lee</a>,
			<a href="https://alanspike.github.io/" style="font-size: 1.2rem; color: white !important;">Jian Ren</a>,
			<a href="https://faculty.ucmerced.edu/mhyang/" style="font-size: 1.2rem; color: white !important;">Ming-Hsuan Yang</a>,
			<a href="http://www.stulyakov.com/" style="font-size: 1.2rem; color: white !important;">Sergey Tulyakov</a>
			<br>
			<a href="https://research.snap.com/team/category/creative-vision"><img class="paper-btn" src="./assets/snap.svg" style="height: 80px; width: auto; margin-top: 50px; margin-bottom: 30px; background-color: #18191a;"></a>
			<a href="https://www.ucmerced.edu/"><img class="paper-btn" src="./assets/ucmerced.svg" style="height: 80px; width: auto; margin-top: 50px; margin-bottom: 30px; margin-left: 30px; background-color: #18191a;"></a>
			<div class="paper-btn-parent">
			<a class="paper-btn" href="https://arxiv.org/pdf/2402.00000.pdf">Read research paper</a>
			<a class="paper-btn" style="width: 80px" href="https://github.com/snap-research/Panda-70M">Github</a>
			<a class="paper-btn" href="./more_samples.html">View more samples</a>
			</div>
			<br><br><br>
		</div>
	</section>

	<div style="display: flex; justify-content: space-around; flex-wrap: wrap; margin-top: -65px;">
		<div class="video-teaser-container">
			<video autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/CkPpCpixOMI.22.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>A blue off-road truck is driving on a sand dune and jumping into the air.</p>
			</div>
		</div>
		<div class="video-teaser-container">
			<video autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/Nuia1y8ZfhE.13.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>There are ants tunneling under a thick carpet of moss.</p>
			</div>
		</div>
		<div class="video-teaser-container">
			<video autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/AIyw1FO1aqs.57.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>A person is holding a long haired dachshund in their arms.</p>
			</div>
		</div>
		<div class="video-teaser-container">
			<video autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/1rKiSD4A1K4.28.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>There is a river flowing through a forest and the water is flowing downstream.</p>
			</div>
		</div>

		<div class="video-teaser-container" style="margin-top: -6px;">
			<video autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/7axksThlAok.79.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>A group of basketball players are practicing their shots on the court.</p>
			</div>
		</div>
		<div class="video-teaser-container" style="margin-top: -6px;">
			<video autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/Kb8ON0iCs38.97.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>A rocket launches into space on the launch pad.</p>
			</div>
		</div>
		<div class="video-teaser-container" style="margin-top: -6px;">
			<video autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/RYbjJ2TpGMo.10.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>Someone is frying dough balls in a pan with oil.</p>
			</div>
		</div>
		<div class="video-teaser-container" style="margin-top: -6px;">
			<video autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/AvVDsFBc6bA.0.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>A person is kneading dough and putting jam on it.</p>
			</div>
		</div>

		<div class="video-teaser-container" style="margin-top: -6px;">
			<video autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/fjSw0PBrtMU.45.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>A person is driving a boat on a river with rocks and waterfalls.</p>
			</div>
		</div>
		<div class="video-teaser-container" style="margin-top: -6px;">
			<video autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/pKIEP-MOCu0.47.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>A woman is playing golf at an outdoor driving range.</p>
			</div>
		</div>

		<div class="video-teaser-container" style="margin-top: -6px;">
			<video autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/1NMpoAqzJfY.25.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>It is a rally car driving on a dirt road in the countryside, with people watching from the side of the road.</p>
			</div>
		</div>
		<div class="video-teaser-container" style="margin-top: -6px;">
			<video autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/5HXiHnvBhI4.30.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>The waves are crashing on the beach and the water is foamy.</p>
			</div>
		</div>
		<div class="video-teaser-container" style="margin-top: -6px;">
			<video autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/aIPu1xGNbhc.49.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>A rhino and a lion are fighting in the dirt.</p>
			</div>
		</div>
		<div class="video-teaser-container" style="margin-top: -6px;">
			<video autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/8glWcEuxw3U.1.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>A blue toyota tacoma truck is parked in a parking lot surrounded by trees.</p>
			</div>
		</div>
		<div class="video-teaser-container" style="margin-top: -6px;">
			<video autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/YYPLi7kGUdU.12.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>A person is making a pie crust on a table.</p>
			</div>
		</div>
		<div class="video-teaser-container" style="margin-top: -6px;">
			<video autoplay="autoplay" loop="loop" muted="muted" type="video/mp4" class="video-teaser" src="./assets/samples/6AXZJTgpusY.3.mp4"></video>
			<div class="hover-overlay responsive-text">
				<p>A large pile of lava blocking a road.</p>
			</div>
		</div>
		<div class="container text-center footnote">
			We will remove the video samples from our dataset / Github / project webpage as long as you need it. Please contact tsaishienchen at gmail dot com for the request.
		</div>
	</div>

	<section id="download">
		<div class="container text-center" style="margin-top: 10px">
			<h1 class="jumbotron-heading">Download Panda-70M</h1>
			<div style="display: flex; justify-content: space-around; flex-wrap: wrap">
				<table class="download-table">
					<tr>
						<td><a class="paper-btn" style="width: 200px" href="https://drive.google.com/file/d/1DeODUcdJCEfnTjJywM-ObmrlVg-wsvwz/view?usp=sharing">Training [full] (2.01 GB)</a></td>
						<td>70.7M samples / 167 khrs duration / ~36 TB</td>
					</tr>
					<tr>
						<td><a class="paper-btn" style="width: 200px" href="https://drive.google.com/file/d/1Lrsb65HTJ2hS7Iuy6iPCmjoc3abbEcAX/view?usp=sharing">Training [10M] (381 MB)</a></td>
						<td>10.5M samples / 37.0 khrs duration / ~8.0 TB</td>
					</tr>
					<tr>
						<td><a class="paper-btn" style="width: 200px" href="https://drive.google.com/file/d/1jWTNGjb-hkKiPHXIbEA5CnFwjhA-Fq_Q/view?usp=sharing">Training [2M] (86.5 MB)</a></td>
						<td>2.4M samples / 7.56 khrs duration / ~1.6 TB</td>
					</tr>
					<tr>
						<td><a class="paper-btn" style="width: 200px" href="https://drive.google.com/file/d/1cTCaC7oJ9ZMPSax6I4ZHvUT-lqxOktrX/view?usp=sharing">Validation (803 KB)</a></td>
						<td>6000 samples / 18.5 hrs duration / ~4.0 GB</td>
					</tr>
					<tr>
						<td><a class="paper-btn" style="width: 200px" href="https://drive.google.com/file/d/1ee227tHEO-DT8AkX7y2q6-bfAtUL-yMI/view?usp=sharing">Testing (803 KB)</a></td>
						<td>6000 samples / 18.5 hrs duration / ~4.0 GB</td>
					</tr>
				</table>
			</div>
			<a class="paper-btn" style="width: 260px" href="https://github.com/snap-research/Panda-70M/dataset_dataloading">Code for Dataset Downloading</a>
			<p style="font-weight: 200; margin-top: 10px;">
				The video samples are collected from the publicy available dataset.<br>
				Users must follow <a href="https://raw.githubusercontent.com/microsoft/XPretrain/main/hd-vila-100m/LICENSE" style="color: white !important;">the related license</a> to use these video samples.
			</p>
		</div>
	</section>

	<hr class="mt-5">

	<section id="collection">
		<div class="container text-center">
			<h1 class="jumbotron-heading">Collection Pipeline of Panda-70M</h1>
			<div style="display: flex; justify-content: space-around; flex-wrap: wrap; margin-top: 30px">
				<video autoplay="autoplay" controls="controls" loop="loop" muted="muted" class="video" type="video/mp4" src="./assets/pipeline.mp4" ></video>
				<p style="font-weight: 200; margin-top: 10px;">
					We first collect 3.8M long videos from HD-VILA-100M dataset and split it into 70.8M semantically coherent clips <a style="background-color:#2e5496">(blue)</a>.
					Next, we utilize a number of teacher models with different multimodal inputs to generate multiple captions for a video clip <a style="background-color:#528135">(green)</a>.
					Lastly, we finetune a fine-grained retrieval model to select the caption that best describes the video clip as the annotation <a style="background-color:#bf9001">(yellow)</a>.
				</p>
			</div>
		</div>
	</section>

	<hr class="mt-5">

	<section id="demo">
		<div class="container text-center">	
			<h1 class="jumbotron-heading">Demo of Long Video Annotation</h1>
			<div style="display: flex; justify-content: space-around; flex-wrap: wrap; margin-top: 30px">
				<p style="font-weight: 200; margin-top: 5px;">
					We demo our splitting and captioning algorithm on long videos (scroll to view more).
					The results are shown in the subtitles:
				</p>
			</div>
			<div class="scroll-container" style="margin-top: -1px;">
				<video autoplay="autoplay" controls="controls" loop="loop" muted="muted" class="video" style="height: 360px; width: auto;">
					<source src="./assets/long_videos/---h-Df_mHE.mp4" type="video/mp4">
					<track src="./assets/long_videos/---h-Df_mHE.vtt" kind="subtitles" label="English" srclang="en" default>
				</video>
				<video autoplay="autoplay" controls="controls" loop="loop" muted="muted" class="video" style="height: 360px; width: auto;">
					<source src="./assets/long_videos/--8k8hhrnxM.mp4" type="video/mp4">
					<track src="./assets/long_videos/--8k8hhrnxM.vtt" kind="subtitles" label="English" srclang="en" default>
				</video>
				<video autoplay="autoplay" controls="controls" loop="loop" muted="muted" class="video" style="height: 360px; width: auto;">
					<source src="./assets/long_videos/--8tWKpDDRA.mp4" type="video/mp4">
					<track src="./assets/long_videos/--8tWKpDDRA.vtt" kind="subtitles" label="English" srclang="en" default>
				</video>
				<video autoplay="autoplay" controls="controls" loop="loop" muted="muted" class="video" style="height: 360px; width: auto;">
					<source src="./assets/long_videos/--5Uy5YZMjA.mp4" type="video/mp4">
					<track src="./assets/long_videos/--5Uy5YZMjA.vtt" kind="subtitles" label="English" srclang="en" default>
				</video>
				<video autoplay="autoplay" controls="controls" loop="loop" muted="muted" class="video" style="height: 360px; width: auto;">
					<source src="./assets/long_videos/--4kpNp60Sc.mp4" type="video/mp4">
					<track src="./assets/long_videos/--4kpNp60Sc.vtt" kind="subtitles" label="English" srclang="en" default>
				</video>
				<video autoplay="autoplay" controls="controls" loop="loop" muted="muted" class="video" style="height: 360px; width: auto;">
					<source src="./assets/long_videos/--1ApFKwvjE.mp4" type="video/mp4">
					<track src="./assets/long_videos/--1ApFKwvjE.vtt" kind="subtitles" label="English" srclang="en" default>
				</video>
				<video autoplay="autoplay" controls="controls" loop="loop" muted="muted" class="video" style="height: 360px; width: auto;">
					<source src="./assets/long_videos/--56B73oBjg.mp4" type="video/mp4">
					<track src="./assets/long_videos/--56B73oBjg.vtt" kind="subtitles" label="English" srclang="en" default>
				</video>
				<video autoplay="autoplay" controls="controls" loop="loop" muted="muted" class="video" style="height: 360px; width: auto;">
					<source src="./assets/long_videos/--BHf7lnQ_0.mp4" type="video/mp4">
					<track src="./assets/long_videos/--BHf7lnQ_0.vtt" kind="subtitles" label="English" srclang="en" default>
				</video>
			</div>
			<div class="container text-center footnote">
				We will remove the video samples from our dataset / Github / project webpage as long as you need it. Please contact tsaishienchen at gmail dot com for the request.
			</div>
		</div>
	</section>

	<hr class="mt-5">

	<section id="statistic">
		<div class="container text-center">
			<h1 class="jumbotron-heading">Statistic</h1>
			<div style="justify-content: space-around; flex-wrap: wrap; margin-top: 30px">
				<div class="image-item">
					<img src="./assets/statistic.svg" style="margin-top: -20px;">
				</div>
				<div class="image-item">
					<img src="./assets/worldcloud.svg" style="margin-top: 10px; margin-bottom: 10px; width: 90%">
				</div>
			</div>
		</div>
	</section>

	<hr class="mt-5">

	<section id="performance">
		<div class="container text-left">
			<h1 class="jumbotron-heading text-center">Performance</h1>
			<div style="justify-content: space-around; flex-wrap: wrap; margin-top: 30px">
				<div class="image-item">
					<img src="./assets/performance.svg" style="margin-top: -20px; margin-bottom: -20px;">
				</div>
				<p style="font-weight: 200">
					We show the value of Panda-70M on three downstream tasks.
					We compare the models training on the existing dataset and the proposed dataset.
					For a fair comparison, we use the same model architecture, same training configuration, and same amount of training data for all comparisons. For more details:
				</p>
			</div>
			<div style="display: flex; justify-content: space-around; flex-wrap: wrap; margin-top: 20px">
				<a class="paper-btn" href="https://arxiv.org/pdf/2402.00000.pdf">Read research paper</a>
			</div>
		</div>
	</section>

	<hr class="mt-5">

	<section id="acknowledgement">
		<div class="container text-left">
			<h1 class="jumbotron-heading text-center">Acknowledgement</h1>
			<div style="display: flex; justify-content: space-around; flex-wrap: wrap; margin-top: 20px">
				<p style="font-weight: 200">
					We sincerely thank to everyone who contributed to the meaningful discussions,
					and also extend our gratitude to Snap Inc. for providing the computational resources and fostering a conducive research environment. &#129303; &#128591; &#128123;
				</p>
			</div>
		</div>
	</section>
	
	<div class="container text-center footnote">
		<p style="font-weight: 200; margin-top: 10px;">
			Copyright &#169; Snap Inc. 2024. This dataset is made available by Snap Inc. for informational purposes only. No license, whether implied or otherwise, is granted in or to such dataset (including any rights to copy, modify, publish, distribute and/or commercialize such dataset), unless you have entered into a separate agreement for such rights. Such dataset is provided as-is, without warranty of any kind, express or implied, including any warranties of merchantability, title, fitness for a particular purpose, non-infringement, or that such dataset is free of defects, errors or viruses. In no event will Snap Inc. be liable for any damages or losses of any kind arising from the dataset or your use thereof.
		</p>
	</div>

	<script>
		document.addEventListener('DOMContentLoaded', function() {
			const links = document.querySelectorAll('a[href^="#"]');
			
			links.forEach(link => {
			link.addEventListener('click', function(e) {
				e.preventDefault();
				
				const targetId = this.getAttribute('href').substring(1);
				const targetElement = document.getElementById(targetId);
				
				if (targetElement) {
				window.scrollTo({
					top: targetElement.offsetTop,
					behavior: 'smooth'
				});
				}
			});
			});
		});

		document.addEventListener("DOMContentLoaded", function() {
			const imageItems = document.querySelectorAll('.image-item');

			function toggleImageVisibility() {
				const scrollPosition = window.scrollY;

				imageItems.forEach(item => {
					const elementPosition = item.getBoundingClientRect().top;

					if (elementPosition < window.innerHeight * 0.7) {
						item.style.opacity = '1';
					} else {
						item.style.opacity = '0';
					}
				});
			}

			// Listen for scroll events
			window.addEventListener('scroll', function() {
				toggleImageVisibility();
			});
		});

		function updateFontSizeForClass(className) {
			var elements = document.getElementsByClassName(className);
			var screenWidth = window.innerWidth || document.documentElement.clientWidth || document.body.clientWidth;

			for (var i = 0; i < elements.length; i++) {
				// Adjust the threshold and font size as needed
				if (screenWidth < 800) {
					elements[i].style.fontSize = "8px";
				} else if (screenWidth < 1000) {
					elements[i].style.fontSize = "12px";
				} else {
					elements[i].style.fontSize = "16px";
				}
			}
		}

		// Call the function on page load and window resize
		window.onload = function() {
			updateFontSizeForClass("responsive-text");
		};
		window.onresize = function() {
			updateFontSizeForClass("responsive-text");
		};
	</script>

</body>
</html>